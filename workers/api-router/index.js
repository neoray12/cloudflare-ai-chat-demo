import { Router } from 'itty-router'

const router = Router()

// AI Gateway å’Œå„ç¨® AI æ¨¡å‹çš„æ•´åˆ
class AIGatewayClient {
  constructor(env) {
    this.env = env
    this.gatewayUrl = env.AI_GATEWAY_URL
  }

  // æ ¹æ“šæ¨¡å‹ ID ç²å– Workers AI æ¨¡å‹è·¯å¾‘
  getWorkerAIModelPath(modelId) {
    const modelMappings = {
      'workers-ai-gpt-oss-120b': '@cf/openai/gpt-oss-120b',
      'workers-ai-gpt-oss-20b': '@cf/openai/gpt-oss-20b', 
      // æš«æ™‚ç§»é™¤ DeepSeek æ¨¡å‹ï¼Œç›´åˆ°ç¢ºèªæ­£ç¢ºè·¯å¾‘
      // 'workers-ai-deepseek-r1': '@cf/deepseek-ai/deepseek-r1-distill-qwen-32b',
      'workers-ai-llama': '@cf/meta/llama-3.1-8b-instruct'
    }
    
    return modelMappings[modelId] || '@cf/meta/llama-3.1-8b-instruct'
  }

  // å°‡å‰ç«¯æ¨¡å‹å€¼è½‰æ›ç‚ºç”¨æˆ¶å‹å¥½çš„æ¨¡å‹åç¨±ï¼ˆç”¨æ–¼ metadataï¼‰
  getModelDisplayName(model) {
    const displayNames = {
      'workers-ai-gpt-oss-120b': 'gpt-oss-120b',
      'workers-ai-gpt-oss-20b': 'gpt-oss-20b',
      'workers-ai-deepseek-r1': 'deepseek-r1-distill-qwen-32b',
      'workers-ai-llama': 'llama-3.1-8b',
      'openai-gpt-3.5': 'gpt-3.5-turbo',
      'openai-gpt-5': 'gpt-5',
      'perplexity-sonar': 'sonar-small-online',
      // å‘å¾Œç›¸å®¹èˆŠçš„æ¨¡å‹åç¨±
      'worker-ai': 'llama-3.1-8b',
      'gpt': 'gpt-3.5-turbo',
      'perplexity': 'sonar-small-online'
    }
    
    return displayNames[model] || model
  }

  // ç²å– OpenAI æ¨¡å‹åç¨±
  getOpenAIModelName(model) {
    const modelMappings = {
      'openai-gpt-3.5': 'gpt-3.5-turbo',
      'openai-gpt-5': 'gpt-5',
      // å‘å¾Œç›¸å®¹
      'gpt': 'gpt-3.5-turbo'
    }
    return modelMappings[model] || 'gpt-3.5-turbo'
  }

  async callWorkerAI(message, modelId, metadata = {}) {
    try {
      // æº–å‚™ headers
      const headers = {
        'Content-Type': 'application/json',
        'cf-aig-authorization': `Bearer ${this.env.CLOUDFLARE_API_TOKEN}`,
        'Authorization': `Bearer ${this.env.WORKER_AI_TOKEN}`
      }

      // åŠ å…¥ custom metadata (æœ€å¤š 5 å€‹)
      if (Object.keys(metadata).length > 0) {
        headers['cf-aig-metadata'] = JSON.stringify(metadata)
        console.log('ğŸ”— WorkerAI - Adding cf-aig-metadata header:', JSON.stringify(metadata))
      }

      // æ ¹æ“šæ¨¡å‹ ID é¸æ“‡æ­£ç¢ºçš„æ¨¡å‹è·¯å¾‘
      const modelPath = this.getWorkerAIModelPath(modelId)
      console.log(`ğŸ¤– Using Workers AI model: ${modelPath}`)

      // æ ¹æ“šæ¨¡å‹é¡å‹æ±ºå®šè«‹æ±‚æ ¼å¼
      let requestBody
      if (modelPath.includes('gpt-oss') || modelPath.includes('deepseek')) {
        // å°æ–¼ text-generation æ¨¡å‹ä½¿ç”¨ input æ ¼å¼
        requestBody = { input: message }
        console.log('ğŸ“ Using text-generation format (input) for:', modelPath)
      } else {
        // å°æ–¼ chat æ¨¡å‹ä½¿ç”¨ messages æ ¼å¼
        requestBody = { messages: [{ role: 'user', content: message }] }
        console.log('ğŸ’¬ Using chat format (messages) for:', modelPath)
      }

      // é€é Cloudflare AI Gateway èª¿ç”¨ Workers AI
      const response = await fetch(`${this.gatewayUrl}/workers-ai/${modelPath}`, {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody)
      })

      if (!response.ok) {
        const errorData = await response.text()
        
        // ç‰¹åˆ¥è™•ç† 429 é™æµéŒ¯èª¤
        if (response.status === 429) {
          throw new Error('Error Code 429ï¼Œä½¿ç”¨æµé‡å·²è¶…éï¼ŒAI Gateway é™æµè¦å‰‡è§¸ç™¼')
        }
        
        throw new Error(`Worker AI Gateway éŒ¯èª¤: ${response.status} - ${errorData}`)
      }

      const data = await response.json()
      console.log('ğŸ” WorkerAI Response structure:', JSON.stringify(data, null, 2))
      
      // æ ¹æ“šæ¨¡å‹é¡å‹å’Œ API å›å‚³æ ¼å¼èª¿æ•´
      if (modelPath.includes('gpt-oss') || modelPath.includes('deepseek')) {
        // æ–°çš„ gpt-oss å’Œ deepseek æ¨¡å‹å›æ‡‰æ ¼å¼
        // çµæ§‹: data.result.output[1].content[0].text (message éƒ¨åˆ†)
        const output = data.result?.output
        if (output && Array.isArray(output) && output.length > 1) {
          // å°‹æ‰¾ type: "message" çš„è¼¸å‡º
          const messageOutput = output.find(item => item.type === 'message')
          if (messageOutput && messageOutput.content && messageOutput.content[0]) {
            const extractedText = messageOutput.content[0].text || ''
            console.log('âœ… Successfully extracted text from Workers AI response:', extractedText.substring(0, 100) + '...')
            return extractedText
          } else {
            console.error('âŒ Could not find message content in Workers AI response')
          }
        } else {
          console.error('âŒ Invalid or missing output array in Workers AI response')
        }
        // å¾Œå‚™è§£æé‚è¼¯
        return data.result?.response || data.result || data.output || ''
      } else {
        // chat æ¨¡å‹çš„å›æ‡‰æ ¼å¼
        return data.result?.response || data.result || data.choices?.[0]?.message?.content || ''
      }
    } catch (error) {
      console.error('Worker AI èª¿ç”¨å¤±æ•—:', error)
      throw error
    }
  }

  async callOpenAI(message, model = 'gpt-3.5-turbo', metadata = {}, stream = true, images = null) {
    try {
      // æª¢æŸ¥å¿…è¦çš„ API å¯†é‘°
      if (!this.env.CLOUDFLARE_API_TOKEN) {
        throw new Error('Cloudflare API Token æœªè¨­å®šã€‚è«‹åœ¨ .dev.vars æª”æ¡ˆä¸­è¨­å®š CLOUDFLARE_API_TOKEN')
      }

      // æº–å‚™ headers
      const headers = {
        'Content-Type': 'application/json',
        'cf-aig-authorization': `Bearer ${this.env.CLOUDFLARE_API_TOKEN}`
      }

      // åŠ å…¥ custom metadata (æœ€å¤š 5 å€‹)
      if (Object.keys(metadata).length > 0) {
        headers['cf-aig-metadata'] = JSON.stringify(metadata)
        console.log('ğŸ”— OpenAI - Adding cf-aig-metadata header:', JSON.stringify(metadata))
      }

      // æ§‹å»ºæ¶ˆæ¯å…§å®¹
      let messageContent = []
      
      // å¦‚æœæœ‰æ–‡æœ¬ï¼Œæ·»åŠ æ–‡æœ¬å…§å®¹
      if (message && message.trim() !== '') {
        messageContent.push({
          type: 'text',
          text: message
        })
      }
      
      // å¦‚æœæœ‰åœ–ç‰‡ï¼Œæ·»åŠ åœ–ç‰‡å…§å®¹
      if (images && Array.isArray(images) && images.length > 0) {
        for (const img of images) {
          // æ§‹å»º base64 URL æ ¼å¼ï¼šdata:image/{mimeType};base64,{base64}
          const imageUrl = `data:${img.mimeType};base64,${img.base64}`
          messageContent.push({
            type: 'image_url',
            image_url: {
              url: imageUrl
            }
          })
        }
      }
      
      // å¦‚æœæ²’æœ‰ä»»ä½•å…§å®¹ï¼Œä½¿ç”¨é»˜èªæ–‡æœ¬
      if (messageContent.length === 0) {
        messageContent.push({
          type: 'text',
          text: 'è«‹åˆ†æé€™äº›åœ–ç‰‡'
        })
      }

      // æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡æ­£ç¢ºçš„åƒæ•¸
      // gpt-5 å’Œå…¶ä»–æ–°æ¨¡å‹ä½¿ç”¨ max_completion_tokensï¼ŒèˆŠæ¨¡å‹ä½¿ç”¨ max_tokens
      const requestBody = {
        model: model,
        messages: [{ role: 'user', content: messageContent }],
        stream: stream
      }

      // å°æ–¼ gpt-5 å’Œæ–°æ¨¡å‹ä½¿ç”¨ max_completion_tokens
      if (model === 'gpt-5' || model.startsWith('gpt-5')) {
        requestBody.max_completion_tokens = 1000
      } else {
        // å°æ–¼èˆŠæ¨¡å‹ä½¿ç”¨ max_tokensï¼ˆå‘å¾Œå…¼å®¹ï¼‰
        requestBody.max_tokens = 1000
      }

      // é€é AI Gateway èª¿ç”¨ OpenAI API (ä½¿ç”¨ BYOK)
      const response = await fetch(`${this.gatewayUrl}/openai/chat/completions`, {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody)
      })

      if (!response.ok) {
        const errorData = await response.text()
        
        // ç‰¹åˆ¥è™•ç† 429 é™æµéŒ¯èª¤
        if (response.status === 429) {
          throw new Error('Error Code 429ï¼Œä½¿ç”¨æµé‡å·²è¶…éï¼ŒAI Gateway é™æµè¦å‰‡è§¸ç™¼')
        }
        
        throw new Error(`OpenAI API éŒ¯èª¤: ${response.status} - ${errorData}`)
      }

      // å¦‚æœæ˜¯ streaming modeï¼Œè¿”å› response å¯¹è±¡ä¾›ä¸Šå±‚å¤„ç†
      if (stream) {
        return response
      }

      // é streaming mode çš„åŸæœ‰é€»è¾‘
      const data = await response.json()
      return data.choices[0].message.content
    } catch (error) {
      console.error('OpenAI èª¿ç”¨å¤±æ•—:', error)
      throw error
    }
  }

  async callPerplexity(message, metadata = {}) {
    try {
      // æº–å‚™ headers
      const headers = {
        'accept': 'application/json',
        'content-type': 'application/json',
        'cf-aig-authorization': `Bearer ${this.env.CLOUDFLARE_API_TOKEN}`
      }

      // åŠ å…¥ custom metadata (æœ€å¤š 5 å€‹)
      if (Object.keys(metadata).length > 0) {
        headers['cf-aig-metadata'] = JSON.stringify(metadata)
        console.log('ğŸ”— Perplexity - Adding cf-aig-metadata header:', JSON.stringify(metadata))
      }

      // é€é Cloudflare AI Gateway èª¿ç”¨ Perplexity API (ä½¿ç”¨ BYOK)
      const response = await fetch(`${this.gatewayUrl}/perplexity-ai/chat/completions`, {
        method: 'POST',
        headers,
        body: JSON.stringify({
          model: 'sonar',
          messages: [{ role: 'user', content: message }]
        })
      })

      if (!response.ok) {
        const errorData = await response.text()
        
        // ç‰¹åˆ¥è™•ç† 429 é™æµéŒ¯èª¤
        if (response.status === 429) {
          throw new Error('Error Code 429ï¼Œä½¿ç”¨æµé‡å·²è¶…éï¼ŒAI Gateway é™æµè¦å‰‡è§¸ç™¼')
        }
        
        throw new Error(`Perplexity Gateway éŒ¯èª¤: ${response.status} - ${errorData}`)
      }

      const data = await response.json()
      return data.choices[0].message.content
    } catch (error) {
      console.error('Perplexity èª¿ç”¨å¤±æ•—:', error)
      throw error
    }
  }

  async processMessage(message, model, metadata = {}, stream = false) {
    // è™•ç† Workers AI æ¨¡å‹
    if (model.startsWith('workers-ai-')) {
      return await this.callWorkerAI(message, model, metadata)
    }
    
    // è™•ç†å…¶ä»–æ¨¡å‹
    switch (model) {
      case 'openai-gpt-3.5':
      case 'openai-gpt-5':
        const openaiModel = this.getOpenAIModelName(model)
        return await this.callOpenAI(message, openaiModel, metadata, stream)
      case 'perplexity-sonar':
        return await this.callPerplexity(message, metadata)
      // å‘å¾Œç›¸å®¹èˆŠçš„æ¨¡å‹åç¨±
      case 'worker-ai':
        return await this.callWorkerAI(message, 'workers-ai-llama', metadata)
      case 'gpt':
        return await this.callOpenAI(message, 'gpt-3.5-turbo', metadata, stream)
      case 'perplexity':
        return await this.callPerplexity(message, metadata)
      default:
        throw new Error(`ä¸æ”¯æ´çš„æ¨¡å‹: ${model}`)
    }
  }
}

// CORS ä¸­ä»‹è»Ÿé«”
const corsHeaders = {
  'Access-Control-Allow-Origin': '*',
  'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS',
  'Access-Control-Allow-Headers': 'Content-Type, Authorization',
}

// è™•ç† OPTIONS è«‹æ±‚
router.options('*', () => new Response(null, { headers: corsHeaders }))

// å¥åº·æª¢æŸ¥
router.get('/api/health', () => {
  return new Response(JSON.stringify({ status: 'healthy' }), {
    headers: { 'Content-Type': 'application/json', ...corsHeaders }
  })
})

// ç”¨æˆ¶ç™»éŒ„ç«¯é»
router.post('/api/auth/login', async (request, env) => {
  try {
    const { username, password, turnstileToken } = await request.json()
    
    if (!username || !password) {
      return new Response(JSON.stringify({ error: 'ç¼ºå°‘å¿…è¦åƒæ•¸' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    // æ ¹æ“šç’°å¢ƒæª¢æŸ¥ Turnstile é©—è­‰
    const isProduction = env.ENVIRONMENT === 'production'
    
    if (isProduction && turnstileToken) {
      const turnstileResponse = await fetch('https://challenges.cloudflare.com/turnstile/v0/siteverify', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          secret: env.TURNSTILE_SECRET_KEY,
          response: turnstileToken
        })
      })

      const turnstileResult = await turnstileResponse.json()
      if (!turnstileResult.success) {
        return new Response(JSON.stringify({ error: 'Turnstile é©—è­‰å¤±æ•—' }), {
          status: 400,
          headers: { 'Content-Type': 'application/json', ...corsHeaders }
        })
      }
    } else if (isProduction && !turnstileToken) {
      return new Response(JSON.stringify({ error: 'ç”Ÿç”¢ç’°å¢ƒéœ€è¦ Turnstile é©—è­‰' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    // ç°¡å–®çš„å¯†ç¢¼ hashï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨ bcryptï¼‰
    const encoder = new TextEncoder()
    const data = encoder.encode(password)
    const hashBuffer = await crypto.subtle.digest('SHA-256', data)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    const passwordHash = hashArray.map(b => b.toString(16).padStart(2, '0')).join('')

    // å¾ D1 æŸ¥è©¢ç”¨æˆ¶ï¼ˆåŒ…å« user_tierï¼‰
    const user = await env.DB.prepare(
      'SELECT id, username, password_hash, email, user_tier, is_active FROM users WHERE username = ? AND is_active = 1'
    ).bind(username).first()

    if (!user || user.password_hash !== passwordHash) {
      // è¨˜éŒ„ç™»éŒ„å¤±æ•—
      await env.DB.prepare(
        'INSERT INTO login_logs (user_id, ip_address, user_agent, success) VALUES (?, ?, ?, ?)'
      ).bind(user?.id || null, request.headers.get('CF-Connecting-IP') || 'unknown', 
             request.headers.get('User-Agent') || 'unknown', false).run()

      return new Response(JSON.stringify({ error: 'ç”¨æˆ¶åæˆ–å¯†ç¢¼éŒ¯èª¤' }), {
        status: 401,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    // è¨˜éŒ„ç™»éŒ„æˆåŠŸ
    await env.DB.prepare(
      'INSERT INTO login_logs (user_id, ip_address, user_agent, success) VALUES (?, ?, ?, ?)'
    ).bind(user.id, request.headers.get('CF-Connecting-IP') || 'unknown', 
           request.headers.get('User-Agent') || 'unknown', true).run()

    // ç”Ÿæˆç°¡å–®çš„ JWT tokenï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•ï¼‰
    const token = btoa(JSON.stringify({
      userId: user.id,
      username: user.username,
      email: user.email,
      userTier: user.user_tier,
      exp: Date.now() + 24 * 60 * 60 * 1000 // 24å°æ™‚éæœŸ
    }))

    return new Response(JSON.stringify({ 
      success: true, 
      token,
      user: {
        id: user.id,
        username: user.username,
        email: user.email,
        userTier: user.user_tier
      }
    }), {
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })

  } catch (error) {
    console.error('ç™»éŒ„éŒ¯èª¤:', error)
    return new Response(JSON.stringify({ error: 'ç™»éŒ„å¤±æ•—', details: error.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })
  }
})

// é©—è­‰ token ç«¯é»
router.post('/api/auth/verify', async (request, env) => {
  try {
    const { token } = await request.json()
    
    if (!token) {
      return new Response(JSON.stringify({ error: 'ç¼ºå°‘ token' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    const decoded = JSON.parse(atob(token))
    if (decoded.exp < Date.now()) {
      return new Response(JSON.stringify({ error: 'Token å·²éæœŸ' }), {
        status: 401,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    return new Response(JSON.stringify({ 
      success: true, 
      user: {
        id: decoded.userId,
        username: decoded.username,
        email: decoded.email,
        userTier: decoded.userTier
      }
    }), {
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })

  } catch (error) {
    console.error('Token é©—è­‰éŒ¯èª¤:', error)
    return new Response(JSON.stringify({ error: 'Token ç„¡æ•ˆ' }), {
      status: 401,
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })
  }
})

// èŠå¤© API ç«¯é»
router.post('/api/chat', async (request, env) => {
  try {
    const body = await request.json()
    const message = body.message ?? body.prompt ?? (Array.isArray(body.messages) && body.messages[0]?.content) ?? null
    const { model, user, images } = body
    
    // æª¢æŸ¥å¿…è¦åƒæ•¸ï¼šè‡³å°‘éœ€è¦ message æˆ– images å…¶ä¸­ä¸€å€‹
    if ((!message || message.trim() === '') && (!images || images.length === 0)) {
      return new Response(JSON.stringify({ error: 'ç¼ºå°‘å¿…è¦åƒæ•¸ï¼šéœ€è¦è¨Šæ¯æˆ–åœ–ç‰‡' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }
    
    if (!model) {
      return new Response(JSON.stringify({ error: 'ç¼ºå°‘å¿…è¦åƒæ•¸ï¼šæ¨¡å‹' }), {
        status: 400,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }
    
    // é©—è­‰åœ–ç‰‡æ•¸æ“šï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if (images && Array.isArray(images) && images.length > 0) {
      // æª¢æŸ¥åœ–ç‰‡æ•¸é‡é™åˆ¶
      if (images.length > 10) {
        return new Response(JSON.stringify({ error: 'åœ–ç‰‡æ•¸é‡è¶…éé™åˆ¶ï¼ˆæœ€å¤š 10 å¼µï¼‰' }), {
          status: 400,
          headers: { 'Content-Type': 'application/json', ...corsHeaders }
        })
      }
      
      // é©—è­‰åœ–ç‰‡æ ¼å¼å’Œå¤§å°
      for (const img of images) {
        if (!img.base64 || !img.mimeType) {
          return new Response(JSON.stringify({ error: 'åœ–ç‰‡æ•¸æ“šæ ¼å¼éŒ¯èª¤ï¼šç¼ºå°‘ base64 æˆ– mimeType' }), {
            status: 400,
            headers: { 'Content-Type': 'application/json', ...corsHeaders }
          })
        }
        
        // é©—è­‰ mimeType
        const validMimeTypes = ['image/jpeg', 'image/png', 'image/webp']
        if (!validMimeTypes.includes(img.mimeType)) {
          return new Response(JSON.stringify({ error: `ä¸æ”¯æŒçš„åœ–ç‰‡æ ¼å¼ï¼š${img.mimeType}` }), {
            status: 400,
            headers: { 'Content-Type': 'application/json', ...corsHeaders }
          })
        }
        
        // é©—è­‰ base64 å¤§å°ï¼ˆè€ƒæ…® base64 ç·¨ç¢¼å¾Œå¢åŠ ç´„ 33%ï¼‰
        const base64Size = (img.base64.length * 3) / 4
        if (base64Size > 10 * 1024 * 1024) {
          return new Response(JSON.stringify({ error: 'åœ–ç‰‡å¤§å°è¶…éé™åˆ¶ï¼ˆæ¯å¼µæœ€å¤§ 10MBï¼‰' }), {
            status: 400,
            headers: { 'Content-Type': 'application/json', ...corsHeaders }
          })
        }
      }
    }

    // ç”ŸæˆèŠå¤© ID
    const chatId = crypto.randomUUID()
    const timestamp = new Date().toISOString()

    // æª¢æŸ¥ KV å¿«å–ï¼ˆé streaming æ¨¡å¼æ‰ä½¿ç”¨å¿«å–ï¼‰
    const encoder = new TextEncoder()
    const data = encoder.encode(message)
    const hashBuffer = await crypto.subtle.digest('SHA-256', data)
    const hashArray = Array.from(new Uint8Array(hashBuffer))
    const hashHex = hashArray.map(b => b.toString(16).padStart(2, '0')).join('')
    const cacheKey = `chat:${model}:${hashHex.slice(0, 32)}`
    
    // æª¢æŸ¥æ˜¯å¦ç‚º OpenAI æ¨¡å‹ï¼ˆéœ€è¦ streamingï¼‰
    const isOpenAIModel = model === 'openai-gpt-3.5' || model === 'openai-gpt-5' || model === 'gpt'
    
    // èª¿ç”¨ AI æ¨¡å‹ä¸¦å‚³é metadata
    const aiClient = new AIGatewayClient(env)
    
    // å»ºæ§‹ custom metadata
    const metadata = {}
    if (user) {
      metadata.username = user.username
      metadata.email = user.email
      metadata.userTier = user.userTier
    }
    metadata.model = aiClient.getModelDisplayName(model)

    // Debug: è¨˜éŒ„ metadata
    console.log('ğŸ“Š Custom Metadata:', JSON.stringify(metadata, null, 2))
    console.log('ğŸ‘¤ User data received:', user ? 'Yes' : 'No')
    console.log('ğŸ” Metadata keys count:', Object.keys(metadata).length)
    console.log('ğŸ“‹ Request body contains:', { message: !!message, model: !!model, user: !!user })

    // å¦‚æœæ˜¯ OpenAI æ¨¡å‹ï¼Œä½¿ç”¨ streaming mode
    if (isOpenAIModel) {
      const streamResponse = await aiClient.processMessage(message, model, metadata, true, images)
      
      if (!streamResponse || !streamResponse.body) {
        throw new Error('ç„¡æ³•ç²å–æµå¼éŸ¿æ‡‰')
      }

      // å‰µå»ºä¸€å€‹æ–°çš„ ReadableStream ä¾†è™•ç† OpenAI çš„æµå¼éŸ¿æ‡‰
      const stream = new ReadableStream({
        async start(controller) {
          const reader = streamResponse.body.getReader()
          const decoder = new TextDecoder()
          const encoder = new TextEncoder()
          let buffer = ''
          let fullContent = ''

          try {
            while (true) {
              const { done, value } = await reader.read()
              
              if (done) {
                // å„²å­˜å®Œæ•´å°è©±è¨˜éŒ„
                try {
                  const chatData = {
                    id: chatId,
                    userId: 'anonymous',
                    model,
                    timestamp,
                    messages: [
                      {
                        role: 'user',
                        content: message,
                        images: images && images.length > 0 ? images.map(img => ({ mimeType: img.mimeType })) : undefined,
                        timestamp
                      },
                      {
                        role: 'assistant',
                        content: fullContent,
                        timestamp: new Date().toISOString()
                      }
                    ]
                  }

                  const r2Key = `chat-${chatId}.json`
                  await env.STORAGE.put(r2Key, JSON.stringify(chatData, null, 2), {
                    httpMetadata: {
                      contentType: 'application/json',
                    }
                  })

                  await env.DB.prepare(
                    'INSERT INTO chats (id, user_id, created_at, r2_key, model) VALUES (?, ?, ?, ?, ?)'
                  ).bind(chatId, 'anonymous', timestamp, r2Key, model).run()
                } catch (storageError) {
                  console.error('å„²å­˜å¤±æ•—:', storageError)
                }

                // ç™¼é€çµæŸæ¨™è¨˜
                controller.enqueue(encoder.encode('data: [DONE]\n\n'))
                controller.close()
                break
              }

              // è™•ç†æµå¼æ•¸æ“š
              buffer += decoder.decode(value, { stream: true })
              const lines = buffer.split('\n')
              buffer = lines.pop() || ''

              for (const line of lines) {
                if (line.startsWith('data: ')) {
                  const data = line.slice(6)
                  if (data === '[DONE]') {
                    continue
                  }

                  try {
                    const json = JSON.parse(data)
                    const content = json.choices?.[0]?.delta?.content || ''
                    if (content) {
                      fullContent += content
                      // ç™¼é€ SSE æ ¼å¼çš„æ•¸æ“š
                      controller.enqueue(encoder.encode(`data: ${JSON.stringify({ content })}\n\n`))
                    }
                  } catch (e) {
                    console.error('è§£æ SSE æ•¸æ“šå¤±æ•—:', e)
                  }
                }
              }
            }
          } catch (error) {
            console.error('æµå¼è™•ç†éŒ¯èª¤:', error)
            controller.error(error)
          }
        }
      })

      return new Response(stream, {
        headers: {
          'Content-Type': 'text/event-stream',
          'Cache-Control': 'no-cache',
          'Connection': 'keep-alive',
          ...corsHeaders
        }
      })
    }

    // é OpenAI æ¨¡å‹æˆ–é streaming æ¨¡å¼ï¼Œä½¿ç”¨åŸæœ‰é‚è¼¯
    const cached = await env.CACHE.get(cacheKey)
    
    if (cached) {
      console.log('å¾å¿«å–è¿”å›çµæœ')
      return new Response(cached, {
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    const aiResponse = await aiClient.processMessage(message, model, metadata, false, images)
    console.log('ğŸ¯ Final AI Response to be sent to frontend:', aiResponse ? aiResponse.substring(0, 100) + '...' : 'EMPTY')

    // å»ºç«‹å®Œæ•´çš„èŠå¤©è¨˜éŒ„
    const chatData = {
      id: chatId,
      userId: 'anonymous',
      model,
      timestamp,
      messages: [
        {
          role: 'user',
          content: message,
          images: images && images.length > 0 ? images.map(img => ({ mimeType: img.mimeType })) : undefined,
          timestamp
        },
        {
          role: 'assistant',
          content: aiResponse,
          timestamp: new Date().toISOString()
        }
      ]
    }

    // å„²å­˜åˆ° R2
    try {
      const r2Key = `chat-${chatId}.json`
      await env.STORAGE.put(r2Key, JSON.stringify(chatData, null, 2), {
        httpMetadata: {
          contentType: 'application/json',
        }
      })

      // å„²å­˜å…ƒæ•¸æ“šåˆ° D1
      await env.DB.prepare(
        'INSERT INTO chats (id, user_id, created_at, r2_key, model) VALUES (?, ?, ?, ?, ?)'
      ).bind(chatId, 'anonymous', timestamp, r2Key, model).run()
    } catch (storageError) {
      console.error('å„²å­˜å¤±æ•—:', storageError)
      // å³ä½¿å„²å­˜å¤±æ•—ï¼Œä»ç„¶è¿”å› AI å›æ‡‰
    }

    // å¿«å–çµæœï¼ˆ1å°æ™‚TTLï¼‰
    const result = { result: aiResponse }
    try {
      await env.CACHE.put(cacheKey, JSON.stringify(result), {
        expirationTtl: 3600
      })
    } catch (cacheError) {
      console.error('å¿«å–å¤±æ•—:', cacheError)
    }

    return new Response(JSON.stringify(result), {
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })

  } catch (error) {
    console.error('API Router éŒ¯èª¤:', error)
    return new Response(JSON.stringify({ error: 'å…§éƒ¨ä¼ºæœå™¨éŒ¯èª¤', details: error.message }), {
      status: 500,
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })
  }
})

// ç²å–èŠå¤©æ­·å²
router.get('/api/chats/:chatId', async (request, env) => {
  try {
    const { chatId } = request.params
    
    // å¾ R2 ç²å–èŠå¤©è¨˜éŒ„
    const object = await env.STORAGE.get(`chat-${chatId}.json`)
    
    if (!object) {
      return new Response(JSON.stringify({ error: 'èŠå¤©è¨˜éŒ„ä¸å­˜åœ¨' }), {
        status: 404,
        headers: { 'Content-Type': 'application/json', ...corsHeaders }
      })
    }

    const chatData = await object.json()
    
    return new Response(JSON.stringify(chatData), {
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })

  } catch (error) {
    console.error('ç²å–èŠå¤©æ­·å²éŒ¯èª¤:', error)
    return new Response(JSON.stringify({ error: 'ç„¡æ³•ç²å–èŠå¤©è¨˜éŒ„' }), {
      status: 500,
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })
  }
})

// åˆ—å‡ºæ‰€æœ‰èŠå¤©
router.get('/api/chats', async (request, env) => {
  try {
    const { results } = await env.DB.prepare(
      'SELECT id, user_id, created_at, r2_key FROM chats ORDER BY created_at DESC LIMIT 50'
    ).all()

    return new Response(JSON.stringify({ chats: results }), {
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })

  } catch (error) {
    console.error('åˆ—å‡ºèŠå¤©éŒ¯èª¤:', error)
    return new Response(JSON.stringify({ error: 'ç„¡æ³•ç²å–èŠå¤©åˆ—è¡¨' }), {
      status: 500,
      headers: { 'Content-Type': 'application/json', ...corsHeaders }
    })
  }
})

// è™•ç†æ‰€æœ‰æœªåŒ¹é…çš„è«‹æ±‚
router.all('*', () => {
  return new Response(JSON.stringify({ error: 'æ‰¾ä¸åˆ°è«‹æ±‚çš„è³‡æº' }), {
    status: 404,
    headers: { 'Content-Type': 'application/json', ...corsHeaders }
  })
})

export default {
  async fetch(request, env, ctx) {
    return router.handle(request, env, ctx)
  }
} 